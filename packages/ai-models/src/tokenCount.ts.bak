import {
  encode,
  encodeChat,
  decode,
  isWithinTokenLimit,
  encodeGenerator,
  decodeGenerator,
  decodeAsyncGenerator,
} from 'gpt-tokenizer'

// Map model names to encodings based on https://github.com/niieani/gpt-tokenizer/blob/HEAD/src/models.ts
const modelToEncoding: Record<string, string> = {
  // GPT-4o, GPT-4, GPT-3.5-turbo, etc.
  'gpt-4o': 'cl100k_base',
  'gpt-4': 'cl100k_base',
  'gpt-4-32k': 'cl100k_base',
  'gpt-4-1106-preview': 'cl100k_base',
  'gpt-4-0125-preview': 'cl100k_base',
  'gpt-4-0613': 'cl100k_base',
  'gpt-4-32k-0613': 'cl100k_base',
  'gpt-3.5-turbo': 'cl100k_base',
  'gpt-3.5-turbo-16k': 'cl100k_base',
  'gpt-3.5-turbo-0613': 'cl100k_base',
  'gpt-3.5-turbo-16k-0613': 'cl100k_base',
  'text-embedding-ada-002': 'cl100k_base',
  // Add more mappings as needed
};

/**
 * Counts the number of tokens in a string for a given OpenAI model.
 * @param text The input string to tokenize.
 * @param model The model name (e.g., 'gpt-4o', 'gpt-4', 'gpt-3.5-turbo').
 * @returns The number of tokens.
 */
export function countGptTokens(text: string, model: string): number {
  const encodingName = modelToEncoding[model] || 'cl100k_base';

  const withinTokenLimit = isWithinTokenLimit(text, tokenLimit)

}
